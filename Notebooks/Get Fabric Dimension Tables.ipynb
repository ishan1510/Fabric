{"cells":[{"cell_type":"markdown","source":["## Reference Links\n","\n","https://github.com/microsoft/semantic-link-labs\n","\n","https://semantic-link-labs.readthedocs.io/en/stable/sempy_labs.admin.html\n","\n","https://github.com/microsoft/semantic-link-labs/blob/main/notebooks/Service%20Principal.ipynb\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b151bece-1589-48cc-8ad7-8a0b3630e11d"},{"cell_type":"markdown","source":["## Import Libraries"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8fafb8ca-4cae-4e1d-93bd-2048ba69e39f"},{"cell_type":"code","source":["import sempy\n","import sempy.fabric as fabric\n","import sempy_labs as labs\n","from pyspark.sql.functions import col, count\n","from datetime import datetime, timedelta\n","from pyspark.sql.functions import lit\n","from pyspark.sql.types import NullType"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"f6c4d9ad-3a97-49d4-9451-1aedfe3e949d","normalized_state":"finished","queued_time":"2025-09-29T05:58:07.395218Z","session_start_time":null,"execution_start_time":"2025-09-29T05:58:07.3962407Z","execution_finish_time":"2025-09-29T05:58:07.8227267Z","parent_msg_id":"1bfe4bbf-e80d-4b94-bda6-d2001c45f31b"},"text/plain":"StatementMeta(, f6c4d9ad-3a97-49d4-9451-1aedfe3e949d, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"561a6ea7-e29b-4972-baa7-7b52d25e3dbe"},{"cell_type":"code","source":["spark.conf.set(\"spark.databricks.delta.properties.defaults.minWriterVersion\", 5)\n","spark.conf.set(\"spark.databricks.delta.properties.defaults.minReaderVersion\", 2)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"f6c4d9ad-3a97-49d4-9451-1aedfe3e949d","normalized_state":"finished","queued_time":"2025-09-29T05:34:18.8714366Z","session_start_time":null,"execution_start_time":"2025-09-29T05:34:18.8724527Z","execution_finish_time":"2025-09-29T05:34:19.3101912Z","parent_msg_id":"ae4a122b-0d5f-4f8c-a060-9614423fd021"},"text/plain":"StatementMeta(, f6c4d9ad-3a97-49d4-9451-1aedfe3e949d, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"817818f7-0326-4a01-9b72-6a1722b74a31"},{"cell_type":"markdown","source":["#### Get workspaces"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8eba7fa3-01ce-4b58-b198-831e81ef4f66"},{"cell_type":"code","source":["df_workspaces = labs.admin.list_workspaces()\n","\n","# Create a spark dataframe\n","spark_df_workspaces = spark.createDataFrame(df_workspaces)\n","\n","# 1. Add IsDeleted column with default value 0 and Deleted On as null\n","\n","spark_df_workspaces = (\n","    spark_df_workspaces\n","    .withColumn(\"IsDeleted\", lit(0))\n","    .withColumn(\"Deleted On\", lit(None))\n",")\n","# ----------------- Run below block on Day 0 -----------------------------\n","\n","# Create table add load data\n","# spark_df_workspaces.write.format(\"Delta\").mode(\"Overwrite\").option(\"delta.columnMapping.mode\", \"name\").saveAsTable(\"dim_workspaces\")\n","\n","\n","\n","# --------------- Run below block for daily load -------------------------\n","# Register as a temp view\n","spark_df_workspaces.createOrReplaceTempView(\"v_workspace\")\n","\n","# Merge into the target Delta table\n","spark.sql(\"\"\"\n","MERGE INTO LH_Monitoring.dbo.dim_workspaces AS t\n","USING v_workspace AS s\n","ON t.`Id` = s.`Id`\n","WHEN MATCHED THEN \n","    UPDATE SET *\n","WHEN NOT MATCHED THEN \n","    INSERT *\n","WHEN NOT MATCHED BY SOURCE AND t.IsDeleted = 0 THEN\n","    UPDATE SET t.IsDeleted = 1,\n","               t.`Deleted On` = now()\n","\"\"\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":27,"statement_ids":[27],"state":"finished","livy_statement_state":"available","session_id":"32648a51-8325-4373-a5f9-26f069eae04a","normalized_state":"finished","queued_time":"2025-09-28T11:03:25.5815376Z","session_start_time":null,"execution_start_time":"2025-09-28T11:03:25.582726Z","execution_finish_time":"2025-09-28T11:03:33.5931604Z","parent_msg_id":"4f9d8928-d892-4cdc-8bab-02c8fa517ba7"},"text/plain":"StatementMeta(, 32648a51-8325-4373-a5f9-26f069eae04a, 27, Finished, Available, Finished)"},"metadata":{}},{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"},"metadata":{}}],"execution_count":23,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"68647c85-59e8-4386-bd3c-4ed6c385c1e3"},{"cell_type":"markdown","source":["#### Get reports"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fae6b9ea-a98f-483d-b5cd-85593e5d1d12"},{"cell_type":"code","source":["df_reports = labs.admin.list_reports()\n","\n","# Create a spark dataframe\n","spark_df_report = spark.createDataFrame(df_reports)\n","\n","\n","# Add IsDeleted column with default value 0 and \"Deleted On\" column with default value None\n","spark_df_report = spark_df_report.withColumn(\"IsDeleted\", lit(0)).withColumn(\"Deleted On\", lit(None))\n","\n","# ----------------- Run below block on Day 0 -----------------------------\n","# spark_df_report.write.format(\"Delta\").mode(\"Overwrite\").option(\"delta.columnMapping.mode\", \"name\").saveAsTable(\"dim_reports\")\n","\n","\n","# --------------- Run below block for daily load -------------------------\n","# Register as a temp view\n","spark_df_report.createOrReplaceTempView(\"v_report\")\n","\n","# Load the target Delta table\n","spark.sql(\"\"\"\n","MERGE INTO LH_Monitoring.dbo.dim_reports as t USING v_report as s \n","ON t.`Report Id` = s.`Report Id` \n","WHEN MATCHED THEN UPDATE SET *\n","WHEN NOT MATCHED THEN INSERT *\n","WHEN NOT MATCHED BY SOURCE AND t.IsDeleted = 0 \n","THEN UPDATE SET t.IsDeleted = 1, t.`Deleted On` = now()\n","\"\"\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":18,"statement_ids":[18],"state":"finished","livy_statement_state":"available","session_id":"f6c4d9ad-3a97-49d4-9451-1aedfe3e949d","normalized_state":"finished","queued_time":"2025-09-29T06:05:51.2652478Z","session_start_time":null,"execution_start_time":"2025-09-29T06:05:51.2662722Z","execution_finish_time":"2025-09-29T06:06:01.1336654Z","parent_msg_id":"4a607bcc-ca7d-4ec2-94f2-d45b1202ce44"},"text/plain":"StatementMeta(, f6c4d9ad-3a97-49d4-9451-1aedfe3e949d, 18, Finished, Available, Finished)"},"metadata":{}},{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"},"metadata":{}}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e139e71b-6476-4449-80c8-3b3c2633de2c"},{"cell_type":"markdown","source":["#### Get datasets"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d3566483-589a-4695-a7fd-10e3ccdbc148"},{"cell_type":"code","source":["df_datasets = labs.admin.list_datasets()\n","# display(df_datasets)\n","\n","# Create a spark dataframe\n","spark_df_datasets = spark.createDataFrame(df_datasets)\n","\n","spark_df_datasets = spark_df_datasets.withColumn(\"Users\",col(\"Users\").cast(\"string\")).withColumn(\"Upstream Datasets\",col(\"Upstream Datasets\").cast(\"string\"))\n","# 1. Add IsDeleted column with default value 0 and Deleted On as null\n","\n","spark_df_datasets = (\n","    spark_df_datasets\n","    .withColumn(\"IsDeleted\", lit(0))\n","    .withColumn(\"Deleted On\", lit(None))\n",")\n","\n","# ----------------- Run below block on Day 0 -----------------------------\n","# spark_df_datasets.write.format(\"Delta\").mode(\"Overwrite\").option(\"delta.columnMapping.mode\", \"name\").saveAsTable(\"dim_datasets\")\n","\n","\n","# --------------- Run below block for daily load -------------------------\n","# Register as a temp view\n","spark_df_datasets.createOrReplaceTempView(\"v_dataset\")\n","\n","# Merge into the target Delta table\n","spark.sql(\"\"\"\n","MERGE INTO LH_Monitoring.dbo.dim_datasets AS t\n","USING v_dataset AS s\n","ON t.`Dataset Id` = s.`Dataset Id`\n","WHEN MATCHED THEN \n","    UPDATE SET *\n","WHEN NOT MATCHED THEN \n","    INSERT *\n","WHEN NOT MATCHED BY SOURCE AND t.IsDeleted = 0 THEN\n","    UPDATE SET t.IsDeleted = 1,\n","               t.`Deleted On` = now()\n","\"\"\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[17],"state":"finished","livy_statement_state":"available","session_id":"f6c4d9ad-3a97-49d4-9451-1aedfe3e949d","normalized_state":"finished","queued_time":"2025-09-29T06:01:52.7096563Z","session_start_time":null,"execution_start_time":"2025-09-29T06:01:52.7107983Z","execution_finish_time":"2025-09-29T06:02:00.6937977Z","parent_msg_id":"6a3d98eb-0b13-4935-a824-a2a39ff16277"},"text/plain":"StatementMeta(, f6c4d9ad-3a97-49d4-9451-1aedfe3e949d, 17, Finished, Available, Finished)"},"metadata":{}},{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"},"metadata":{}}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"00bbbd7d-303a-4ef0-9a75-7d8ad261ce6e"},{"cell_type":"markdown","source":["#### Get Fabric Items"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6db3c4cd-4560-4c49-aeba-7217c3e3d863"},{"cell_type":"code","source":["df_lists = labs.admin.list_items()\n","# display(df_lists)\n","\n","# Create a spark dataframe\n","spark_df_lists = spark.createDataFrame(df_lists)\n","\n","# Add IsDeleted column with default value 0 and Deleted On as null\n","spark_df_lists = (\n","    spark_df_lists\n","    .withColumn(\"IsDeleted\", lit(0))\n","    .withColumn(\"Deleted On\", lit(None))\n",")\n","\n","# ----------------- Run below block on Day 0 -----------------------------\n","# spark_df_lists.write.format(\"Delta\").mode(\"Overwrite\").option(\"delta.columnMapping.mode\", \"name\").saveAsTable(\"dim_items\")\n","\n","\n","# --------------- Run below block for daily load -------------------------\n","# Register as a temp view\n","spark_df_lists.createOrReplaceTempView(\"v_item\")\n","\n","# Merge into the target Delta table\n","spark.sql(\"\"\"\n","MERGE INTO LH_Monitoring.dbo.dim_items AS t\n","USING v_item AS s\n","ON t.`Item Id` = s.`Item Id`\n","WHEN MATCHED THEN \n","    UPDATE SET *\n","WHEN NOT MATCHED THEN \n","    INSERT *\n","WHEN NOT MATCHED BY SOURCE AND t.IsDeleted = 0 THEN\n","    UPDATE SET t.IsDeleted = 1,\n","               t.`Deleted On` = now()\n","\"\"\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":35,"statement_ids":[35],"state":"finished","livy_statement_state":"available","session_id":"32648a51-8325-4373-a5f9-26f069eae04a","normalized_state":"finished","queued_time":"2025-09-28T11:15:17.5686911Z","session_start_time":null,"execution_start_time":"2025-09-28T11:15:17.5696859Z","execution_finish_time":"2025-09-28T11:15:23.9040778Z","parent_msg_id":"4d677f23-fac7-4b84-80f6-71d320ed8cce"},"text/plain":"StatementMeta(, 32648a51-8325-4373-a5f9-26f069eae04a, 35, Finished, Available, Finished)"},"metadata":{}},{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"},"metadata":{}}],"execution_count":27,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7026664e-5949-4bad-b5f5-ec367c2bce28"},{"cell_type":"markdown","source":["#### Get Domains"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8e071168-29e4-45bd-afe9-35bff2a44f8a"},{"cell_type":"code","source":["df_domains = labs.admin.list_domains()\n","# display(df_domains)\n","\n","# Create a spark dataframe\n","spark_df_domains = spark.createDataFrame(df_domains)\n","\n","spark_df_domains = spark_df_domains.withColumn(\"Parent Domain ID\",col(\"Parent Domain ID\").cast(\"string\"))\n","\n","# Add IsDeleted column with default value 0 and Deleted On as null\n","spark_df_domains = (\n","    spark_df_domains\n","    .withColumn(\"IsDeleted\", lit(0))\n","    .withColumn(\"Deleted On\", lit(None))\n",")\n","\n","# ----------------- Run below block on Day 0 -----------------------------\n","# spark_df_domains.write.format(\"Delta\").mode(\"Overwrite\").option(\"delta.columnMapping.mode\", \"name\").saveAsTable(\"dim_domains\")\n","\n","\n","# --------------- Run below block for daily load -------------------------\n","# Register as a temp view\n","spark_df_domains.createOrReplaceTempView(\"v_domain\")\n","\n","# Merge into the target Delta table\n","spark.sql(\"\"\"\n","MERGE INTO LH_Monitoring.dbo.dim_domains AS t\n","USING v_domain AS s\n","ON t.`Domain Id` = s.`Domain Id`\n","WHEN MATCHED THEN \n","    UPDATE SET *\n","WHEN NOT MATCHED THEN \n","    INSERT *\n","WHEN NOT MATCHED BY SOURCE AND t.IsDeleted = 0 THEN\n","    UPDATE SET t.IsDeleted = 1,\n","               t.`Deleted On` = now()\n","\"\"\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"f6c4d9ad-3a97-49d4-9451-1aedfe3e949d","normalized_state":"finished","queued_time":"2025-09-29T05:42:22.0517713Z","session_start_time":null,"execution_start_time":"2025-09-29T05:42:22.0529735Z","execution_finish_time":"2025-09-29T05:42:31.828058Z","parent_msg_id":"9f4a86c3-41e0-4302-bdf3-65d9d1437574"},"text/plain":"StatementMeta(, f6c4d9ad-3a97-49d4-9451-1aedfe3e949d, 10, Finished, Available, Finished)"},"metadata":{}},{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ee6eac00-1922-4a3e-b87d-9175e47416a3"},{"cell_type":"markdown","source":["###### If you have these tables created already you can use below commands to add IsDeleted and \"Deleted On\" columns"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2c8654b6-66f3-44ba-b154-38a71ee9302e"},{"cell_type":"code","source":["%%sql\n","ALTER TABLE LH_Monitoring.dbo.dim_datasets ADD COLUMN IsDeleted int;\n","ALTER TABLE LH_Monitoring.dbo.dim_datasets ADD COLUMN `Deleted On` TIMESTAMP;\n","\n","Update LH_Monitoring.dbo.dim_datasets SET IsDeleted = 0"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"sparksql","language_group":"synapse_pyspark"}},"id":"09dbd482-4fa4-4d48-956f-7669ad4a83ff"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"c69e199d-9923-4b2e-8523-b0d8b4b7c08d","known_lakehouses":[{"id":"c69e199d-9923-4b2e-8523-b0d8b4b7c08d"}],"default_lakehouse_name":"LH_Monitoring","default_lakehouse_workspace_id":"9c9cf6ef-dc0e-4c69-8082-03cb9c63f69c"},"environment":{"environmentId":"04d55a02-83bd-4b51-aab1-95515a3a9ffa","workspaceId":"9c9cf6ef-dc0e-4c69-8082-03cb9c63f69c"}}},"nbformat":4,"nbformat_minor":5}